# EX-02-Cross-Platform-Prompting-Evaluating-Diverse-Techniques-in-AI-Powered-Text-Summarization

## AIM
To evaluate and compare the effectiveness of prompting techniques (zero-shot, few-shot, chain-of-thought, role-based) across different AI platforms (e.g., ChatGPT, Gemini, Claude, Copilot) in a specific task: text summarization.

## Scenario:
You are part of a content curation team for an educational platform that delivers quick summaries of research papers to undergraduate students. Your task is to summarize a 500-word technical article on "The Basics of Blockchain Technology" using multiple AI platforms and prompting strategies.

Your goal is to determine which combination of prompting technique + platform provides the best summary in terms of:

Accuracy

Coherence

Simplicity

Speed

User experience

## Algorithm 
Basic Prompting Across Various Test Scenarios 
Instructions 
1. Define Prompting Techniques 
 Naïve 
Prompting: 
This involves providing ChatGPT with a simple, direct prompt without any additional 
context 
or 
Example: 
"Write a poem about a cat." 
 Basic 
instructions, 
instructions. 
Prompting: 
This technique involves providing ChatGPT with a more structured prompt, including 
specific 
questions, 
Example: 
or 
examples to guide the response. 
"Write a poem about a mischievous cat who loves to play with yarn. Use a rhyming 
scheme of ABAB." 
2. Scenario 
Zero-Shot Prompt 
Prompt: 
"Explain what a large language model is." 
Response: 
A large language model is an advanced type of artificial intelligence trained on massive 
amounts of text data. It uses machine learning techniques to understand and generate human
like text. These models can perform tasks like translation, summarization, and question 
answering by predicting the next word in a sequence based on context. Examples include GPT 
(Generative Pretrained Transformer) models, which can complete sentences, engage in 
conversation, and even write essays or code with high accuracy. 
One-Shot Prompt 
Prompt: 
"Explain what a large language model is. For example, think of it as a tool that can generate 
human-like text based on patterns it has learned from huge amounts of data. It's like a machine 
that can understand and respond to language by predicting the next word in a sentence. Can 
you explain this in more detail?" 
Response: 
A large language model is a type of machine learning model designed to process and generate 
text that mimics human language. It works by analyzing large datasets of text from books, 
articles, websites, and more to learn the structure and nuances of language. Once trained, the 
model can generate coherent sentences by predicting the next word based on the previous 
words, making it capable of tasks like answering questions, writing content, or holding a 
conversation. GPT (Generative Pretrained Transformer) models are popular examples of large 
language models, and they excel in understanding context and producing accurate, contextually 
relevant text. 
3. Design Test Scenarios 
Create a diverse set of test scenarios that cover a range of tasks and topics: 
 Question answering: "What is the capital of Australia?" 
 Creative writing: "Write a short story about a robot who dreams of becoming a chef." 
 Summarization: "Summarize the main points of the article 'The Future of Artificial 
Intelligence.'" 
 Translation: "Translate the sentence 'Hello, how are you?' into Spanish." 
 Code generation: "Write a Python function to calculate the factorial of a number." 
 Problem-solving: "How can I solve the Rubik's Cube?" 
 Open-ended questions: "What do you think about the future of artificial intelligence?" 
 Contextual understanding: "Based on the following information, what is the most 
likely outcome of the situation?" 
4. Conduct Experiments 
 For each test scenario, generate a set of prompts using both naïve and basic prompting 
techniques. 
 Interact with ChatGPT using each prompt and record the responses. 
 Evaluate the quality and relevance of the responses based on the following criteria: 
o Accuracy: Does the response provide correct information? 
o Coherence: Is the response well-structured and easy to understand? 
o Relevance: Does the response address the prompt effectively? 
o Creativity: Is the response original and imaginative? 
o Informativeness: Does the response provide valuable insights or information? 
o Bias: Is the response free from bias or prejudice? 
o Factuality: Does the response contain factual errors or inaccuracies? 
5. Analyze Results 
 Compare the responses generated using naïve prompting and basic prompting for each 
test scenario. 
 Identify patterns and trends in the effectiveness of each technique. 
 Analyze the factors that contribute to the differences in response quality, such as prompt 
specificity, clarity, and relevance. 
 Consider the impact of prompt engineering on ChatGPT's ability to generate creative, 
informative, and accurate responses. 
 Evaluate the ethical implications of using ChatGPT for various tasks, such as the 
potential for generating harmful or misleading content. 
6. Refine Prompts and Experiment Further 
 Based on the initial analysis, refine the prompting techniques used and conduct 
additional experiments to explore different approaches. 
 Consider using more complex prompting techniques, such as role-playing or providing 
examples of desired outputs. 
 Experiment with different ChatGPT models or parameters to see how they affect the 
quality of responses. 
Comparison of Naïve Prompting vs. Basic Prompting 
Criteria 
Accuracy 
Naïve Prompting 
Often 
lacks 
specificity, 
leading to less accurate 
responses. 
Basic Prompting 
Provides 
more context and 
instructions, improving accuracy. 
Coherence 
Relevance 
May produce less coherent 
or structured responses. 
Can be less relevant to the 
prompt, resulting in off-topic 
responses. 
Offers more guidance, leading to 
more coherent and well-structured 
outputs. 
Ensures the response stays on topic 
and 
addresses 
effectively. 
the 
prompt 
Criteria 
Naïve Prompting 
Basic Prompting 
Creativity 
Informativeness 
Bias 
Factuality 
May limit creativity by 
providing 
too 
structure. 
much 
May not provide sufficient 
depth or detail. 
More susceptible to biases 
present in the training data. 
May contain factual errors 
due to lack of context. 
Can encourage creativity by 
providing a framework while 
allowing for flexibility. 
Encourages ChatGPT to provide 
more 
informative 
comprehensive responses. 
and 
Can help mitigate bias by providing 
specific instructions or examples. 
Provides more context, reducing the 
likelihood of factual inaccuracies. 
Overall: Basic prompting generally outperforms naïve prompting in terms of accuracy, 
coherence, relevance, and informativeness. However, the effectiveness of each technique may 
vary depending on the specific task and the complexity of the prompt. 
Deliverables 
1. Comprehensive Report: 
o Introduction to the experiment and its objectives 
o Detailed description of the test scenarios and prompting techniques used 
o Presentation of the experimental results, including quantitative and qualitative 
analysis 
o Discussion of the implications of the findings 
o Conclusions and recommendations for future research 
2. Data Analysis: 
o Statistical analysis of the experimental data to support the findings 
o Visualization of the results (e.g., charts, graphs) 
Conclusion 
Prompt engineering plays a crucial role in effectively interacting with ChatGPT and other large 
language models. By using basic prompting techniques and providing clear, specific 
instructions, users can significantly improve the quality and relevance of the generated 
responses. 
## Result
thus the above program was executed successfully.

